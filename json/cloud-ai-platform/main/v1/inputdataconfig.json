{"id":"aiplatform\/v1\/inputdataconfig","type":"","title":"Google\\Cloud\\AIPlatform\\V1\\InputDataConfig","name":"InputDataConfig","description":"<p>Specifies Vertex AI owned input data to be used for training, and\npossibly evaluating, the Model.<\/p>\n<p>Generated from protobuf message <code>google.cloud.aiplatform.v1.InputDataConfig<\/code><\/p>\n<p>Extends <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/Message.php\" target=\"_blank\">Google\\Protobuf\\Internal\\Message<\/a><\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L182","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.fraction_split\n","description":"<p>Split based on fractions defining the size of each set.<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/fractionsplit\">Google\\Cloud\\AIPlatform\\V1\\FractionSplit<\/a>"],"optional":null,"nullable":null},{"name":"data.filter_split\n","description":"<p>Split based on the provided filters for each set.<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/filtersplit\">Google\\Cloud\\AIPlatform\\V1\\FilterSplit<\/a>"],"optional":null,"nullable":null},{"name":"data.predefined_split\n","description":"<p>Supported only for tabular Datasets. Split based on a predefined key.<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/predefinedsplit\">Google\\Cloud\\AIPlatform\\V1\\PredefinedSplit<\/a>"],"optional":null,"nullable":null},{"name":"data.timestamp_split\n","description":"<p>Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/timestampsplit\">Google\\Cloud\\AIPlatform\\V1\\TimestampSplit<\/a>"],"optional":null,"nullable":null},{"name":"data.stratified_split\n","description":"<p>Supported only for tabular Datasets. Split based on the distribution of the specified column.<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/stratifiedsplit\">Google\\Cloud\\AIPlatform\\V1\\StratifiedSplit<\/a>"],"optional":null,"nullable":null},{"name":"data.gcs_destination\n","description":"<p>The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: <code>dataset-&lt;dataset-id&gt;-&lt;annotation-type&gt;-&lt;timestamp-of-training-call&gt;<\/code> where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: &quot;gs:\/\/...\/training-<em>.jsonl&quot; <\/em> AIP_DATA_FORMAT = &quot;jsonl&quot; for non-tabular data, &quot;csv&quot; for tabular data <em> AIP_TRAINING_DATA_URI = &quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/training-<\/em>.${AIP_DATA_FORMAT}&quot; <em> AIP_VALIDATION_DATA_URI = &quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/validation-<\/em>.${AIP_DATA_FORMAT}&quot; <em> AIP_TEST_DATA_URI = &quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/test-<\/em>.${AIP_DATA_FORMAT}&quot;<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/gcsdestination\">Google\\Cloud\\AIPlatform\\V1\\GcsDestination<\/a>"],"optional":null,"nullable":null},{"name":"data.bigquery_destination\n","description":"<p>Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name <code>dataset_&lt;dataset-id&gt;_&lt;annotation-type&gt;_&lt;timestamp-of-training-call&gt;<\/code> where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, <code>training<\/code>, <code>validation<\/code> and <code>test<\/code>. <em> AIP_DATA_FORMAT = &quot;bigquery&quot;. <\/em> AIP_TRAINING_DATA_URI = &quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.training&quot; <em> AIP_VALIDATION_DATA_URI = &quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.validation&quot; <\/em> AIP_TEST_DATA_URI = &quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.test&quot;<\/p>","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/bigquerydestination\">Google\\Cloud\\AIPlatform\\V1\\BigQueryDestination<\/a>"],"optional":null,"nullable":null},{"name":"data.dataset_id\n","description":"<p>Required. The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's [training_task_definition] [google.cloud.aiplatform.v1.TrainingPipeline.training_task_definition]. For tabular Datasets, all their data is exported to training, to pick and choose from.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null},{"name":"data.annotations_filter\n","description":"<p>Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in [ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations] may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null},{"name":"data.annotation_schema_uri\n","description":"<p>Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 <a href=\"https:\/\/github.com\/OAI\/OpenAPI-Specification\/blob\/main\/versions\/3.0.2.md#schemaObject\">Schema Object<\/a>. The schema files that can be used here are found in gs:\/\/google-cloud-aiplatform\/schema\/dataset\/annotation\/ , note that the chosen schema must be consistent with [metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the Dataset specified by [dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id]. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used for training are filtered by both [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter] and [annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri].<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null},{"name":"data.saved_query_id\n","description":"<p>Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by [dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id] used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used for training are filtered by both [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter]. Only one of [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri] should be specified as both of them represent the same thing: problem type.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getFractionSplit","type":"instance","name":"getFractionSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L193","description":"<p>Split based on fractions defining the size of each set.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.FractionSplit fraction_split = 2;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/fractionsplit\">Google\\Cloud\\AIPlatform\\V1\\FractionSplit<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setFractionSplit","type":"instance","name":"setFractionSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L210","description":"<p>Split based on fractions defining the size of each set.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.FractionSplit fraction_split = 2;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Split based on fractions defining the size of each set.<\/p>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/fractionsplit\">Google\\Cloud\\AIPlatform\\V1\\FractionSplit<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getFilterSplit","type":"instance","name":"getFilterSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L224","description":"<p>Split based on the provided filters for each set.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.FilterSplit filter_split = 3;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/filtersplit\">Google\\Cloud\\AIPlatform\\V1\\FilterSplit<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setFilterSplit","type":"instance","name":"setFilterSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L241","description":"<p>Split based on the provided filters for each set.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.FilterSplit filter_split = 3;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Split based on the provided filters for each set.<\/p>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/filtersplit\">Google\\Cloud\\AIPlatform\\V1\\FilterSplit<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getPredefinedSplit","type":"instance","name":"getPredefinedSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L256","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on a predefined key.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.PredefinedSplit predefined_split = 4;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/predefinedsplit\">Google\\Cloud\\AIPlatform\\V1\\PredefinedSplit<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setPredefinedSplit","type":"instance","name":"setPredefinedSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L274","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on a predefined key.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.PredefinedSplit predefined_split = 4;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on a predefined key.<\/p>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/predefinedsplit\">Google\\Cloud\\AIPlatform\\V1\\PredefinedSplit<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getTimestampSplit","type":"instance","name":"getTimestampSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L289","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the timestamp of the input data pieces.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.TimestampSplit timestamp_split = 5;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/timestampsplit\">Google\\Cloud\\AIPlatform\\V1\\TimestampSplit<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setTimestampSplit","type":"instance","name":"setTimestampSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L307","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the timestamp of the input data pieces.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.TimestampSplit timestamp_split = 5;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the timestamp of the input data pieces.<\/p>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/timestampsplit\">Google\\Cloud\\AIPlatform\\V1\\TimestampSplit<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getStratifiedSplit","type":"instance","name":"getStratifiedSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L322","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the distribution of the specified column.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.StratifiedSplit stratified_split = 12;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/stratifiedsplit\">Google\\Cloud\\AIPlatform\\V1\\StratifiedSplit<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setStratifiedSplit","type":"instance","name":"setStratifiedSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L340","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the distribution of the specified column.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.StratifiedSplit stratified_split = 12;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Supported only for tabular Datasets.<\/p>\n<p>Split based on the distribution of the specified column.<\/p>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/stratifiedsplit\">Google\\Cloud\\AIPlatform\\V1\\StratifiedSplit<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getGcsDestination","type":"instance","name":"getGcsDestination","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L369","description":"<p>The Cloud Storage location where the training data is to be\nwritten to. In the given directory a new directory is created with\nname:\n<code>dataset-&lt;dataset-id&gt;-&lt;annotation-type&gt;-&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.<\/p>\n<p>All training input data is written into that directory.\nThe Vertex AI environment variables representing Cloud Storage\ndata URIs are represented in the Cloud Storage wildcard\nformat to support sharded data. e.g.: &quot;gs:\/\/...\/training-*.jsonl&quot;<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;jsonl&quot; for non-tabular data, &quot;csv&quot; for tabular data<\/li>\n<li>AIP_TRAINING_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/training-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/validation-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/test-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.GcsDestination gcs_destination = 8;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/gcsdestination\">Google\\Cloud\\AIPlatform\\V1\\GcsDestination<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setGcsDestination","type":"instance","name":"setGcsDestination","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L401","description":"<p>The Cloud Storage location where the training data is to be\nwritten to. In the given directory a new directory is created with\nname:\n<code>dataset-&lt;dataset-id&gt;-&lt;annotation-type&gt;-&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.<\/p>\n<p>All training input data is written into that directory.\nThe Vertex AI environment variables representing Cloud Storage\ndata URIs are represented in the Cloud Storage wildcard\nformat to support sharded data. e.g.: &quot;gs:\/\/...\/training-*.jsonl&quot;<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;jsonl&quot; for non-tabular data, &quot;csv&quot; for tabular data<\/li>\n<li>AIP_TRAINING_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/training-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/validation-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/test-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.GcsDestination gcs_destination = 8;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>The Cloud Storage location where the training data is to be\nwritten to. In the given directory a new directory is created with\nname:\n<code>dataset-&lt;dataset-id&gt;-&lt;annotation-type&gt;-&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.<\/p>\n<p>All training input data is written into that directory.\nThe Vertex AI environment variables representing Cloud Storage\ndata URIs are represented in the Cloud Storage wildcard\nformat to support sharded data. e.g.: &quot;gs:\/\/...\/training-*.jsonl&quot;<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;jsonl&quot; for non-tabular data, &quot;csv&quot; for tabular data<\/li>\n<li>AIP_TRAINING_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/training-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/validation-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;gcs_destination\/dataset-<dataset-id>-<annotation-type>-<time>\/test-*.${AIP_DATA_FORMAT}&quot;<\/li>\n<\/ul>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/gcsdestination\">Google\\Cloud\\AIPlatform\\V1\\GcsDestination<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getBigqueryDestination","type":"instance","name":"getBigqueryDestination","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L429","description":"<p>Only applicable to custom training with tabular Dataset with BigQuery\nsource.<\/p>\n<p>The BigQuery project location where the training data is to be written\nto. In the given project a new dataset is created with name\n<code>dataset_&lt;dataset-id&gt;_&lt;annotation-type&gt;_&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training\ninput data is written into that dataset. In the dataset three\ntables are created, <code>training<\/code>, <code>validation<\/code> and <code>test<\/code>.<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;bigquery&quot;.<\/li>\n<li>AIP_TRAINING_DATA_URI  =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.training&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.validation&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.test&quot;<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.BigQueryDestination bigquery_destination = 10;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/bigquerydestination\">Google\\Cloud\\AIPlatform\\V1\\BigQueryDestination<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setBigqueryDestination","type":"instance","name":"setBigqueryDestination","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L460","description":"<p>Only applicable to custom training with tabular Dataset with BigQuery\nsource.<\/p>\n<p>The BigQuery project location where the training data is to be written\nto. In the given project a new dataset is created with name\n<code>dataset_&lt;dataset-id&gt;_&lt;annotation-type&gt;_&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training\ninput data is written into that dataset. In the dataset three\ntables are created, <code>training<\/code>, <code>validation<\/code> and <code>test<\/code>.<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;bigquery&quot;.<\/li>\n<li>AIP_TRAINING_DATA_URI  =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.training&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.validation&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.test&quot;<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>.google.cloud.aiplatform.v1.BigQueryDestination bigquery_destination = 10;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Only applicable to custom training with tabular Dataset with BigQuery\nsource.<\/p>\n<p>The BigQuery project location where the training data is to be written\nto. In the given project a new dataset is created with name\n<code>dataset_&lt;dataset-id&gt;_&lt;annotation-type&gt;_&lt;timestamp-of-training-call&gt;<\/code>\nwhere timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training\ninput data is written into that dataset. In the dataset three\ntables are created, <code>training<\/code>, <code>validation<\/code> and <code>test<\/code>.<\/p>\n<ul>\n<li>AIP_DATA_FORMAT = &quot;bigquery&quot;.<\/li>\n<li>AIP_TRAINING_DATA_URI  =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.training&quot;<\/li>\n<li>AIP_VALIDATION_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.validation&quot;<\/li>\n<li>AIP_TEST_DATA_URI =\n&quot;bigquery<em>destination.dataset<\/em><dataset-id><em><annotation-type><\/em><time>.test&quot;<\/li>\n<\/ul>\n","types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/bigquerydestination\">Google\\Cloud\\AIPlatform\\V1\\BigQueryDestination<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getDatasetId","type":"instance","name":"getDatasetId","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L480","description":"<p>Required. The ID of the Dataset in the same Project and Location which data will be\nused to train the Model. The Dataset must use schema compatible with\nModel being trained, and what is compatible should be described in the\nused TrainingPipeline's [training_task_definition]\n[google.cloud.aiplatform.v1.TrainingPipeline.training_task_definition].<\/p>\n<p>For tabular Datasets, all their data is exported to training, to pick\nand choose from.<\/p>\n<p>Generated from protobuf field <code>string dataset_id = 1 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setDatasetId","type":"instance","name":"setDatasetId","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L498","description":"<p>Required. The ID of the Dataset in the same Project and Location which data will be\nused to train the Model. The Dataset must use schema compatible with\nModel being trained, and what is compatible should be described in the\nused TrainingPipeline's [training_task_definition]\n[google.cloud.aiplatform.v1.TrainingPipeline.training_task_definition].<\/p>\n<p>For tabular Datasets, all their data is exported to training, to pick\nand choose from.<\/p>\n<p>Generated from protobuf field <code>string dataset_id = 1 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. The ID of the Dataset in the same Project and Location which data will be\nused to train the Model. The Dataset must use schema compatible with\nModel being trained, and what is compatible should be described in the\nused TrainingPipeline's [training_task_definition]\n[google.cloud.aiplatform.v1.TrainingPipeline.training_task_definition].<\/p>\n<p>For tabular Datasets, all their data is exported to training, to pick\nand choose from.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getAnnotationsFilter","type":"instance","name":"getAnnotationsFilter","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L520","description":"<p>Applicable only to Datasets that have DataItems and Annotations.<\/p>\n<p>A filter on Annotations of the Dataset. Only Annotations that both\nmatch this filter and belong to DataItems not ignored by the split method\nare used in respectively training, validation or test role, depending on\nthe role of the DataItem they are on (for the auto-assigned that role is\ndecided by Vertex AI). A filter with same syntax as the one used in\n[ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations] may be used, but note\nhere it filters across all Annotations of the Dataset, and not just within\na single DataItem.<\/p>\n<p>Generated from protobuf field <code>string annotations_filter = 6;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setAnnotationsFilter","type":"instance","name":"setAnnotationsFilter","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L540","description":"<p>Applicable only to Datasets that have DataItems and Annotations.<\/p>\n<p>A filter on Annotations of the Dataset. Only Annotations that both\nmatch this filter and belong to DataItems not ignored by the split method\nare used in respectively training, validation or test role, depending on\nthe role of the DataItem they are on (for the auto-assigned that role is\ndecided by Vertex AI). A filter with same syntax as the one used in\n[ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations] may be used, but note\nhere it filters across all Annotations of the Dataset, and not just within\na single DataItem.<\/p>\n<p>Generated from protobuf field <code>string annotations_filter = 6;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Applicable only to Datasets that have DataItems and Annotations.<\/p>\n<p>A filter on Annotations of the Dataset. Only Annotations that both\nmatch this filter and belong to DataItems not ignored by the split method\nare used in respectively training, validation or test role, depending on\nthe role of the DataItem they are on (for the auto-assigned that role is\ndecided by Vertex AI). A filter with same syntax as the one used in\n[ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations] may be used, but note\nhere it filters across all Annotations of the Dataset, and not just within\na single DataItem.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getAnnotationSchemaUri","type":"instance","name":"getAnnotationSchemaUri","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L569","description":"<p>Applicable only to custom training with Datasets that have DataItems and\nAnnotations.<\/p>\n<p>Cloud Storage URI that points to a YAML file describing the annotation\nschema. The schema is defined as an OpenAPI 3.0.2 <a href=\"https:\/\/github.com\/OAI\/OpenAPI-Specification\/blob\/main\/versions\/3.0.2.md#schemaObject\">Schema\nObject<\/a>.\nThe schema files that can be used here are found in\ngs:\/\/google-cloud-aiplatform\/schema\/dataset\/annotation\/ , note that the\nchosen schema must be consistent with\n[metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id].\nOnly Annotations that both match this schema and belong to DataItems not\nignored by the split method are used in respectively training, validation\nor test role, depending on the role of the DataItem they are on.\nWhen used in conjunction with [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used\nfor training are filtered by both [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter] and\n[annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri].<\/p>\n<p>Generated from protobuf field <code>string annotation_schema_uri = 9;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setAnnotationSchemaUri","type":"instance","name":"setAnnotationSchemaUri","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L596","description":"<p>Applicable only to custom training with Datasets that have DataItems and\nAnnotations.<\/p>\n<p>Cloud Storage URI that points to a YAML file describing the annotation\nschema. The schema is defined as an OpenAPI 3.0.2 <a href=\"https:\/\/github.com\/OAI\/OpenAPI-Specification\/blob\/main\/versions\/3.0.2.md#schemaObject\">Schema\nObject<\/a>.\nThe schema files that can be used here are found in\ngs:\/\/google-cloud-aiplatform\/schema\/dataset\/annotation\/ , note that the\nchosen schema must be consistent with\n[metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id].\nOnly Annotations that both match this schema and belong to DataItems not\nignored by the split method are used in respectively training, validation\nor test role, depending on the role of the DataItem they are on.\nWhen used in conjunction with [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used\nfor training are filtered by both [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter] and\n[annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri].<\/p>\n<p>Generated from protobuf field <code>string annotation_schema_uri = 9;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Applicable only to custom training with Datasets that have DataItems and\nAnnotations.<\/p>\n<p>Cloud Storage URI that points to a YAML file describing the annotation\nschema. The schema is defined as an OpenAPI 3.0.2 <a href=\"https:\/\/github.com\/OAI\/OpenAPI-Specification\/blob\/main\/versions\/3.0.2.md#schemaObject\">Schema\nObject<\/a>.\nThe schema files that can be used here are found in\ngs:\/\/google-cloud-aiplatform\/schema\/dataset\/annotation\/ , note that the\nchosen schema must be consistent with\n[metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id].\nOnly Annotations that both match this schema and belong to DataItems not\nignored by the split method are used in respectively training, validation\nor test role, depending on the role of the DataItem they are on.\nWhen used in conjunction with [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used\nfor training are filtered by both [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter] and\n[annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri].<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getSavedQueryId","type":"instance","name":"getSavedQueryId","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L618","description":"<p>Only applicable to Datasets that have SavedQueries.<\/p>\n<p>The ID of a SavedQuery (annotation set) under the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id] used for filtering Annotations for training.\nOnly Annotations that are associated with this SavedQuery are used in\nrespectively training. When used in conjunction with\n[annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used for training are filtered by\nboth [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter].\nOnly one of [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri] should be\nspecified as both of them represent the same thing: problem type.<\/p>\n<p>Generated from protobuf field <code>string saved_query_id = 7;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setSavedQueryId","type":"instance","name":"setSavedQueryId","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L638","description":"<p>Only applicable to Datasets that have SavedQueries.<\/p>\n<p>The ID of a SavedQuery (annotation set) under the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id] used for filtering Annotations for training.\nOnly Annotations that are associated with this SavedQuery are used in\nrespectively training. When used in conjunction with\n[annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used for training are filtered by\nboth [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter].\nOnly one of [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri] should be\nspecified as both of them represent the same thing: problem type.<\/p>\n<p>Generated from protobuf field <code>string saved_query_id = 7;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Only applicable to Datasets that have SavedQueries.<\/p>\n<p>The ID of a SavedQuery (annotation set) under the Dataset specified by\n[dataset_id][google.cloud.aiplatform.v1.InputDataConfig.dataset_id] used for filtering Annotations for training.\nOnly Annotations that are associated with this SavedQuery are used in\nrespectively training. When used in conjunction with\n[annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter], the Annotations used for training are filtered by\nboth [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotations_filter][google.cloud.aiplatform.v1.InputDataConfig.annotations_filter].\nOnly one of [saved_query_id][google.cloud.aiplatform.v1.InputDataConfig.saved_query_id] and [annotation_schema_uri][google.cloud.aiplatform.v1.InputDataConfig.annotation_schema_uri] should be\nspecified as both of them represent the same thing: problem type.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-ai-platform\/main\/aiplatform\/v1\/inputdataconfig\">Google\\Cloud\\AIPlatform\\V1\\InputDataConfig<\/a>"],"description":""}]},{"id":"getSplit","type":"instance","name":"getSplit","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L649","description":"","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"getDestination","type":"instance","name":"getDestination","source":"AiPlatform\/src\/V1\/InputDataConfig.php#L657","description":"","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]}]}