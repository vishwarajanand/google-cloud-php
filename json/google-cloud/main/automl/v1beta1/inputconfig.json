{"id":"automl\/v1beta1\/inputconfig","type":"","title":"Google\\Cloud\\AutoMl\\V1beta1\\InputConfig","name":"InputConfig","description":"<p>Input configuration for ImportData Action.<\/p>\n<p>The format of input depends on dataset_metadata the Dataset into which\nthe import is happening has. As input source the\n[gcs_source][google.cloud.automl.v1beta1.InputConfig.gcs_source]\nis expected, unless specified otherwise. Additionally any input .CSV file\nby itself must be 100MB or smaller, unless specified otherwise.\nIf an &quot;example&quot; file (that is, image, video etc.) with identical content\n(even if it had different GCS_FILE_PATH) is mentioned multiple times, then\nits label, bounding boxes etc. are appended. The same file should be always\nprovided with the same ML_USE and GCS_FILE_PATH, if it is not, then\nthese values are nondeterministically selected from the given ones.\nThe formats are represented in EBNF with commas being literal and with\nnon-terminal symbols defined near the end of this comment. The formats are:<\/p>\n<ul>\n<li>For Image Classification:\nCSV file(s) with each line in format:\nML_USE,GCS_FILE_PATH,LABEL,LABEL,...\nGCS_FILE_PATH leads to image of up to 30MB in size. Supported\nextensions: .JPEG, .GIF, .PNG, .WEBP, .BMP, .TIFF, .ICO\nFor MULTICLASS classification type, at most one LABEL is allowed\nper image. If an image has not yet been labeled, then it should be\nmentioned just once with no LABEL.\nSome sample rows:\nTRAIN,gs:\/\/folder\/image1.jpg,daisy\nTEST,gs:\/\/folder\/image2.jpg,dandelion,tulip,rose\nUNASSIGNED,gs:\/\/folder\/image3.jpg,daisy\nUNASSIGNED,gs:\/\/folder\/image4.jpg<\/li>\n<li>For Image Object Detection:\nCSV file(s) with each line in format:\nML_USE,GCS_FILE_PATH,(LABEL,BOUNDING_BOX | ,,,,,,,)\nGCS_FILE_PATH leads to image of up to 30MB in size. Supported\nextensions: .JPEG, .GIF, .PNG.\nEach image is assumed to be exhaustively labeled. The minimum\nallowed BOUNDING_BOX edge length is 0.01, and no more than 500\nBOUNDING_BOX-es per image are allowed (one BOUNDING_BOX is defined\nper line). If an image has not yet been labeled, then it should be\nmentioned just once with no LABEL and the &quot;,,,,,,,&quot; in place of the\nBOUNDING_BOX. For images which are known to not contain any\nbounding boxes, they should be labelled explictly as\n&quot;NEGATIVE_IMAGE&quot;, followed by &quot;,,,,,,,&quot; in place of the\nBOUNDING_BOX.\nSample rows:\nTRAIN,gs:\/\/folder\/image1.png,car,0.1,0.1,,,0.3,0.3,,\nTRAIN,gs:\/\/folder\/image1.png,bike,.7,.6,,,.8,.9,,\nUNASSIGNED,gs:\/\/folder\/im2.png,car,0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.3\nTEST,gs:\/\/folder\/im3.png,,,,,,,,,\nTRAIN,gs:\/\/folder\/im4.png,NEGATIVE_IMAGE,,,,,,,,,<\/li>\n<li>For Video Classification:\nCSV file(s) with each line in format:\nML_USE,GCS_FILE_PATH\nwhere ML_USE VALIDATE value should not be used. The GCS_FILE_PATH\nshould lead to another .csv file which describes examples that have\ngiven ML_USE, using the following row format:\nGCS_FILE_PATH,(LABEL,TIME_SEGMENT_START,TIME_SEGMENT_END | ,,)\nHere GCS_FILE_PATH leads to a video of up to 50GB in size and up\nto 3h duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI.\nTIME_SEGMENT_START and TIME_SEGMENT_END must be within the\nlength of the video, and end has to be after the start. Any segment\nof a video which has one or more labels on it, is considered a\nhard negative for all other labels. Any segment with no labels on\nit is considered to be unknown. If a whole video is unknown, then\nit shuold be mentioned just once with &quot;,,&quot; in place of LABEL,\nTIME_SEGMENT_START,TIME_SEGMENT_END.\nSample top level CSV file:\nTRAIN,gs:\/\/folder\/train_videos.csv\nTEST,gs:\/\/folder\/test_videos.csv\nUNASSIGNED,gs:\/\/folder\/other_videos.csv\nSample rows of a CSV file for a particular ML_USE:\ngs:\/\/folder\/video1.avi,car,120,180.000021\ngs:\/\/folder\/video1.avi,bike,150,180.000021\ngs:\/\/folder\/vid2.avi,car,0,60.5\ngs:\/\/folder\/vid3.avi,,,<\/li>\n<li>For Video Object Tracking:\nCSV file(s) with each line in format:\nML_USE,GCS_FILE_PATH\nwhere ML_USE VALIDATE value should not be used. The GCS_FILE_PATH\nshould lead to another .csv file which describes examples that have\ngiven ML_USE, using one of the following row format:\nGCS_FILE_PATH,LABEL,[INSTANCE_ID],TIMESTAMP,BOUNDING_BOX\nor\nGCS_FILE_PATH,,,,,,,,,,\nHere GCS_FILE_PATH leads to a video of up to 50GB in size and up\nto 3h duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI.\nProviding INSTANCE_IDs can help to obtain a better model. When\na specific labeled entity leaves the video frame, and shows up\nafterwards it is not required, albeit preferable, that the same\nINSTANCE_ID is given to it.\nTIMESTAMP must be within the length of the video, the\nBOUNDING_BOX is assumed to be drawn on the closest video's frame\nto the TIMESTAMP. Any mentioned by the TIMESTAMP frame is expected\nto be exhaustively labeled and no more than 500 BOUNDING_BOX-es per\nframe are allowed. If a whole video is unknown, then it should be\nmentioned just once with &quot;,,,,,,,,,,&quot; in place of LABEL,\n[INSTANCE_ID],TIMESTAMP,BOUNDING_BOX.\nSample top level CSV file:\nTRAIN,gs:\/\/folder\/train_videos.csv\nTEST,gs:\/\/folder\/test_videos.csv\nUNASSIGNED,gs:\/\/folder\/other_videos.csv\nSeven sample rows of a CSV file for a particular ML_USE:\ngs:\/\/folder\/video1.avi,car,1,12.10,0.8,0.8,0.9,0.8,0.9,0.9,0.8,0.9\ngs:\/\/folder\/video1.avi,car,1,12.90,0.4,0.8,0.5,0.8,0.5,0.9,0.4,0.9\ngs:\/\/folder\/video1.avi,car,2,12.10,.4,.2,.5,.2,.5,.3,.4,.3\ngs:\/\/folder\/video1.avi,car,2,12.90,.8,.2,,,.9,.3,,\ngs:\/\/folder\/video1.avi,bike,,12.50,.45,.45,,,.55,.55,,\ngs:\/\/folder\/video2.avi,car,1,0,.1,.9,,,.9,.1,,\ngs:\/\/folder\/video2.avi,,,,,,,,,,,<\/li>\n<li>For Text Extraction:\nCSV file(s) with each line in format:\nML_USE,GCS_FILE_PATH\nGCS_FILE_PATH leads to a .JSONL (that is, JSON Lines) file which\neither imports text in-line or as documents. Any given\n.JSONL file must be 100MB or smaller.\nThe in-line .JSONL file contains, per line, a proto that wraps a\nTextSnippet proto (in json representation) followed by one or more\nAnnotationPayload protos (called annotations), which have\ndisplay_name and text_extraction detail populated. The given text\nis expected to be annotated exhaustively, for example, if you look\nfor animals and text contains &quot;dolphin&quot; that is not labeled, then\n&quot;dolphin&quot; is assumed to not be an animal. Any given text snippet\ncontent must be 10KB or smaller, and also be UTF-8 NFC encoded\n(ASCII already is).\nThe document .JSONL file contains, per line, a proto that wraps a\nDocument proto. The Document proto must have either document_text\nor input_config set. In document_text case, the Document proto may\nalso contain the spatial information of the document, including\nlayout, document dimension and page number. In input_config case,\nonly PDF documents are supported now, and each document may be up\nto 2MB large. Currently, annotations on documents cannot be\nspecified at import.\nThree sample CSV rows:\nTRAIN,gs:\/\/folder\/file1.jsonl\nVALIDATE,gs:\/\/folder\/file2.jsonl\nTEST,gs:\/\/folder\/file3.jsonl\nSample in-line JSON Lines file for entity extraction (presented here\nwith artificial line breaks, but the only actual line break is\ndenoted by \\n).:\n{\n&quot;document&quot;: {\n&quot;document_text&quot;: {&quot;content&quot;: &quot;dog cat&quot;}\n&quot;layout&quot;: [\n{\n&quot;text_segment&quot;: {\n&quot;start_offset&quot;: 0,\n&quot;end_offset&quot;: 3,\n},\n&quot;page_number&quot;: 1,\n&quot;bounding_poly&quot;: {\n&quot;normalized_vertices&quot;: [\n{&quot;x&quot;: 0.1, &quot;y&quot;: 0.1},\n{&quot;x&quot;: 0.1, &quot;y&quot;: 0.3},\n{&quot;x&quot;: 0.3, &quot;y&quot;: 0.3},\n{&quot;x&quot;: 0.3, &quot;y&quot;: 0.1},\n],\n},\n&quot;text_segment_type&quot;: TOKEN,\n},\n{\n&quot;text_segment&quot;: {\n&quot;start_offset&quot;: 4,\n&quot;end_offset&quot;: 7,\n},\n&quot;page_number&quot;: 1,\n&quot;bounding_poly&quot;: {\n&quot;normalized_vertices&quot;: [\n{&quot;x&quot;: 0.4, &quot;y&quot;: 0.1},\n{&quot;x&quot;: 0.4, &quot;y&quot;: 0.3},\n{&quot;x&quot;: 0.8, &quot;y&quot;: 0.3},\n{&quot;x&quot;: 0.8, &quot;y&quot;: 0.1},\n],\n},\n&quot;text_segment_type&quot;: TOKEN,\n}\n],\n&quot;document_dimensions&quot;: {\n&quot;width&quot;: 8.27,\n&quot;height&quot;: 11.69,\n&quot;unit&quot;: INCH,\n}\n&quot;page_count&quot;: 1,\n},\n&quot;annotations&quot;: [\n{\n&quot;display_name&quot;: &quot;animal&quot;,\n&quot;text_extraction&quot;: {&quot;text_segment&quot;: {&quot;start_offset&quot;: 0,\n&quot;end_offset&quot;: 3}}\n},\n{\n&quot;display_name&quot;: &quot;animal&quot;,\n&quot;text_extraction&quot;: {&quot;text_segment&quot;: {&quot;start_offset&quot;: 4,\n&quot;end_offset&quot;: 7}}\n}\n],\n}\\n\n{\n&quot;text_snippet&quot;: {\n&quot;content&quot;: &quot;This dog is good.&quot;\n},\n&quot;annotations&quot;: [\n{\n&quot;display_name&quot;: &quot;animal&quot;,\n&quot;text_extraction&quot;: {\n&quot;text_segment&quot;: {&quot;start_offset&quot;: 5, &quot;end_offset&quot;: 8}\n}\n}\n]\n}\nSample document JSON Lines file (presented here with artificial line\nbreaks, but the only actual line break is denoted by \\n).:\n{\n&quot;document&quot;: {\n&quot;input_config&quot;: {\n&quot;gcs_source&quot;: { &quot;input_uris&quot;: [ &quot;gs:\/\/folder\/document1.pdf&quot; ]\n}\n}\n}\n}\\n\n{\n&quot;document&quot;: {\n&quot;input_config&quot;: {\n&quot;gcs_source&quot;: { &quot;input_uris&quot;: [ &quot;gs:\/\/folder\/document2.pdf&quot; ]\n}\n}\n}\n}<\/li>\n<li>For Text Classification:\nCSV file(s) with each line in format:\nML_USE,(TEXT_SNIPPET | GCS_FILE_PATH),LABEL,LABEL,...\nTEXT_SNIPPET and GCS_FILE_PATH are distinguished by a pattern. If\nthe column content is a valid gcs file path, i.e. prefixed by\n&quot;gs:\/\/&quot;, it will be treated as a GCS_FILE_PATH, else if the content\nis enclosed within double quotes (&quot;&quot;), it is\ntreated as a TEXT_SNIPPET. In the GCS_FILE_PATH case, the path\nmust lead to a .txt file with UTF-8 encoding, for example,\n&quot;gs:\/\/folder\/content.txt&quot;, and the content in it is extracted\nas a text snippet. In TEXT_SNIPPET case, the column content\nexcluding quotes is treated as to be imported text snippet. In\nboth cases, the text snippet\/file size must be within 128kB.\nMaximum 100 unique labels are allowed per CSV row.\nSample rows:\nTRAIN,&quot;They have bad food and very rude&quot;,RudeService,BadFood\nTRAIN,gs:\/\/folder\/content.txt,SlowService\nTEST,&quot;Typically always bad service there.&quot;,RudeService\nVALIDATE,&quot;Stomach ache to go.&quot;,BadFood<\/li>\n<li>For Text Sentiment:\nCSV file(s) with each line in format:\nML_USE,(TEXT_SNIPPET | GCS_FILE_PATH),SENTIMENT\nTEXT_SNIPPET and GCS_FILE_PATH are distinguished by a pattern. If\nthe column content is a valid gcs file path, that is, prefixed by\n&quot;gs:\/\/&quot;, it is treated as a GCS_FILE_PATH, otherwise it is treated\nas a TEXT_SNIPPET. In the GCS_FILE_PATH case, the path\nmust lead to a .txt file with UTF-8 encoding, for example,\n&quot;gs:\/\/folder\/content.txt&quot;, and the content in it is extracted\nas a text snippet. In TEXT_SNIPPET case, the column content itself\nis treated as to be imported text snippet. In both cases, the\ntext snippet must be up to 500 characters long.\nSample rows:\nTRAIN,&quot;&#64;freewrytin this is way too good for your product&quot;,2\nTRAIN,&quot;I need this product so bad&quot;,3\nTEST,&quot;Thank you for this product.&quot;,4\nVALIDATE,gs:\/\/folder\/content.txt,2\n<ul>\n<li>For Tables:\nEither\n[gcs_source][google.cloud.automl.v1beta1.InputConfig.gcs_source] or\n[bigquery_source][google.cloud.automl.v1beta1.InputConfig.bigquery_source]\ncan be used. All inputs is concatenated into a single\n[primary_table][google.cloud.automl.v1beta1.TablesDatasetMetadata.primary_table_name]\nFor gcs_source:\nCSV file(s), where the first row of the first file is the header,\ncontaining unique column names. If the first row of a subsequent\nfile is the same as the header, then it is also treated as a\nheader. All other rows contain values for the corresponding\ncolumns.\nEach .CSV file by itself must be 10GB or smaller, and their total\nsize must be 100GB or smaller.\nFirst three sample rows of a CSV file:\n&quot;Id&quot;,&quot;First Name&quot;,&quot;Last Name&quot;,&quot;Dob&quot;,&quot;Addresses&quot;\n&quot;1&quot;,&quot;John&quot;,&quot;Doe&quot;,&quot;1968-01-22&quot;,&quot;[{&quot;status&quot;:&quot;current&quot;,&quot;address&quot;:&quot;123_First_Avenue&quot;,&quot;city&quot;:&quot;Seattle&quot;,&quot;state&quot;:&quot;WA&quot;,&quot;zip&quot;:&quot;11111&quot;,&quot;numberOfYears&quot;:&quot;1&quot;},{&quot;status&quot;:&quot;previous&quot;,&quot;address&quot;:&quot;456_Main_Street&quot;,&quot;city&quot;:&quot;Portland&quot;,&quot;state&quot;:&quot;OR&quot;,&quot;zip&quot;:&quot;22222&quot;,&quot;numberOfYears&quot;:&quot;5&quot;}]&quot;\n&quot;2&quot;,&quot;Jane&quot;,&quot;Doe&quot;,&quot;1980-10-16&quot;,&quot;[{&quot;status&quot;:&quot;current&quot;,&quot;address&quot;:&quot;789_Any_Avenue&quot;,&quot;city&quot;:&quot;Albany&quot;,&quot;state&quot;:&quot;NY&quot;,&quot;zip&quot;:&quot;33333&quot;,&quot;numberOfYears&quot;:&quot;2&quot;},{&quot;status&quot;:&quot;previous&quot;,&quot;address&quot;:&quot;321_Main_Street&quot;,&quot;city&quot;:&quot;Hoboken&quot;,&quot;state&quot;:&quot;NJ&quot;,&quot;zip&quot;:&quot;44444&quot;,&quot;numberOfYears&quot;:&quot;3&quot;}]}\nFor bigquery_source:\nAn URI of a BigQuery table. The user data size of the BigQuery\ntable must be 100GB or smaller.\nAn imported table must have between 2 and 1,000 columns, inclusive,\nand between 1000 and 100,000,000 rows, inclusive. There are at most 5\nimport data running in parallel.\nDefinitions:\nML_USE = &quot;TRAIN&quot; | &quot;VALIDATE&quot; | &quot;TEST&quot; | &quot;UNASSIGNED&quot;\nDescribes how the given example (file) should be used for model\ntraining. &quot;UNASSIGNED&quot; can be used when user has no preference.\nGCS_FILE<em>PATH = A path to file on GCS, e.g. &quot;gs:\/\/folder\/image1.png&quot;.\nLABEL = A display name of an object on an image, video etc., e.g. &quot;dog&quot;.\nMust be up to 32 characters long and can consist only of ASCII\nLatin letters A-Z and a-z, underscores(<\/em>), and ASCII digits 0-9.\nFor each label an AnnotationSpec is created which display_name\nbecomes the label; AnnotationSpecs are given back in predictions.\nINSTANCE_ID = A positive integer that identifies a specific instance of a\nlabeled entity on an example. Used e.g. to track two cars on\na video while being able to tell apart which one is which.\nBOUNDING_BOX = VERTEX,VERTEX,VERTEX,VERTEX | VERTEX,,,VERTEX,,\nA rectangle parallel to the frame of the example (image,\nvideo). If 4 vertices are given they are connected by edges\nin the order provided, if 2 are given they are recognized\nas diagonally opposite vertices of the rectangle.\nVERTEX = COORDINATE,COORDINATE\nFirst coordinate is horizontal (x), the second is vertical (y).\nCOORDINATE = A float in 0 to 1 range, relative to total length of\nimage or video in given dimension. For fractions the\nleading non-decimal 0 can be omitted (i.e. 0.3 = .3).\nPoint 0,0 is in top left.\nTIME_SEGMENT_START = TIME_OFFSET\nExpresses a beginning, inclusive, of a time segment\nwithin an example that has a time dimension\n(e.g. video).\nTIME_SEGMENT_END = TIME_OFFSET\nExpresses an end, exclusive, of a time segment within\nan example that has a time dimension (e.g. video).\nTIME_OFFSET = A number of seconds as measured from the start of an\nexample (e.g. video). Fractions are allowed, up to a\nmicrosecond precision. &quot;inf&quot; is allowed, and it means the end\nof the example.\nTEXT_SNIPPET = A content of a text snippet, UTF-8 encoded, enclosed within\ndouble quotes (&quot;&quot;).\nSENTIMENT = An integer between 0 and\nDataset.text_sentiment_dataset_metadata.sentiment_max\n(inclusive). Describes the ordinal of the sentiment - higher\nvalue means a more positive sentiment. All the values are\ncompletely relative, i.e. neither 0 needs to mean a negative or\nneutral sentiment nor sentiment_max needs to mean a positive one\n<ul>\n<li>it is just required that 0 is the least positive sentiment\nin the data, and sentiment_max is the  most positive one.\nThe SENTIMENT shouldn't be confused with &quot;score&quot; or &quot;magnitude&quot;\nfrom the previous Natural Language Sentiment Analysis API.\nAll SENTIMENT values between 0 and sentiment_max must be\nrepresented in the imported data. On prediction the same 0 to\nsentiment_max range will be used. The difference between\nneighboring sentiment values needs not to be uniform, e.g. 1 and\n2 may be similar whereas the difference between 2 and 3 may be\nhuge.\nErrors:\nIf any of the provided CSV files can't be parsed or if more than certain\npercent of CSV rows cannot be processed then the operation fails and\nnothing is imported. Regardless of overall success or failure the per-row\nfailures, up to a certain count cap, is listed in\nOperation.metadata.partial_failures.<\/li>\n<\/ul><\/li>\n<\/ul><\/li>\n<\/ul>\n<p>Generated from protobuf message <code>google.cloud.automl.v1beta1.InputConfig<\/code><\/p>\n<p>Extends <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/Message.php\" target=\"_blank\">Google\\Protobuf\\Internal\\Message<\/a><\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L397","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.gcs_source\n","description":"<p>The Google Cloud Storage location for the input content. In ImportData, the gcs_source points to a csv with structure described in the comment.<\/p>","types":["<a data-custom-type=\"automl\/v1beta1\/gcssource\">Google\\Cloud\\AutoMl\\V1beta1\\GcsSource<\/a>"],"optional":null,"nullable":null},{"name":"data.bigquery_source\n","description":"<p>The BigQuery location for the input content.<\/p>","types":["<a data-custom-type=\"automl\/v1beta1\/bigquerysource\">Google\\Cloud\\AutoMl\\V1beta1\\BigQuerySource<\/a>"],"optional":null,"nullable":null},{"name":"data.params\n","description":"<p>Additional domain-specific parameters describing the semantic of the imported data, any string must be up to 25000 characters long. * For Tables: <code>schema_inference_version<\/code> - (integer) Required. The version of the algorithm that should be used for the initial inference of the schema (columns' DataTypes) of the table the data is being imported into. Allowed values: &quot;1&quot;.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getGcsSource","type":"instance","name":"getGcsSource","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L410","description":"<p>The Google Cloud Storage location for the input content.<\/p>\n<p>In ImportData, the gcs_source points to a csv with structure described in\nthe comment.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.GcsSource gcs_source = 1;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/gcssource\">Google\\Cloud\\AutoMl\\V1beta1\\GcsSource<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setGcsSource","type":"instance","name":"setGcsSource","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L429","description":"<p>The Google Cloud Storage location for the input content.<\/p>\n<p>In ImportData, the gcs_source points to a csv with structure described in\nthe comment.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.GcsSource gcs_source = 1;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>The Google Cloud Storage location for the input content.<\/p>\n<p>In ImportData, the gcs_source points to a csv with structure described in\nthe comment.<\/p>\n","types":["<a data-custom-type=\"automl\/v1beta1\/gcssource\">Google\\Cloud\\AutoMl\\V1beta1\\GcsSource<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/inputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\InputConfig<\/a>"],"description":""}]},{"id":"getBigquerySource","type":"instance","name":"getBigquerySource","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L443","description":"<p>The BigQuery location for the input content.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BigQuerySource bigquery_source = 3;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/bigquerysource\">Google\\Cloud\\AutoMl\\V1beta1\\BigQuerySource<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setBigquerySource","type":"instance","name":"setBigquerySource","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L460","description":"<p>The BigQuery location for the input content.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BigQuerySource bigquery_source = 3;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>The BigQuery location for the input content.<\/p>\n","types":["<a data-custom-type=\"automl\/v1beta1\/bigquerysource\">Google\\Cloud\\AutoMl\\V1beta1\\BigQuerySource<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/inputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\InputConfig<\/a>"],"description":""}]},{"id":"getParams","type":"instance","name":"getParams","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L481","description":"<p>Additional domain-specific parameters describing the semantic of the\nimported data, any string must be up to 25000\ncharacters long.<\/p>\n<ul>\n<li>For Tables:\n<code>schema_inference_version<\/code> - (integer) Required. The version of the\nalgorithm that should be used for the initial inference of the\nschema (columns' DataTypes) of the table the data is being imported\ninto. Allowed values: &quot;1&quot;.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; params = 2;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"description":""}]},{"id":"setParams","type":"instance","name":"setParams","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L500","description":"<p>Additional domain-specific parameters describing the semantic of the\nimported data, any string must be up to 25000\ncharacters long.<\/p>\n<ul>\n<li>For Tables:\n<code>schema_inference_version<\/code> - (integer) Required. The version of the\nalgorithm that should be used for the initial inference of the\nschema (columns' DataTypes) of the table the data is being imported\ninto. Allowed values: &quot;1&quot;.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; params = 2;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Additional domain-specific parameters describing the semantic of the\nimported data, any string must be up to 25000\ncharacters long.<\/p>\n<ul>\n<li>For Tables:\n<code>schema_inference_version<\/code> - (integer) Required. The version of the\nalgorithm that should be used for the initial inference of the\nschema (columns' DataTypes) of the table the data is being imported\ninto. Allowed values: &quot;1&quot;.<\/li>\n<\/ul>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/inputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\InputConfig<\/a>"],"description":""}]},{"id":"getSource","type":"instance","name":"getSource","source":"AutoMl\/src\/V1beta1\/InputConfig.php#L511","description":"","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]}]}