{"id":"speech\/v1p1beta1\/streamingrecognitionconfig","type":"","title":"Google\\Cloud\\Speech\\V1p1beta1\\StreamingRecognitionConfig","name":"StreamingRecognitionConfig","description":"<p>Provides information to the recognizer that specifies how to process the\nrequest.<\/p>\n<p>Generated from protobuf message <code>google.cloud.speech.v1p1beta1.StreamingRecognitionConfig<\/code><\/p>\n<p>Extends <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.9\/src\/Google\/Protobuf\/Internal\/Message.php\" target=\"_blank\">Google\\Protobuf\\Internal\\Message<\/a><\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L94","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.config\n","description":"<p>Required. Provides information to the recognizer that specifies how to process the request.<\/p>","types":["<a data-custom-type=\"speech\/v1p1beta1\/recognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\RecognitionConfig<\/a>"],"optional":null,"nullable":null},{"name":"data.single_utterance\n","description":"<p>If <code>false<\/code> or omitted, the recognizer will perform continuous recognition (continuing to wait for and process audio even if the user pauses speaking) until the client closes the input stream (gRPC API) or until the maximum time limit has been reached. May return multiple <code>StreamingRecognitionResult<\/code>s with the <code>is_final<\/code> flag set to <code>true<\/code>. If <code>true<\/code>, the recognizer will detect a single spoken utterance. When it detects that the user has paused or stopped speaking, it will return an <code>END_OF_SINGLE_UTTERANCE<\/code> event and cease recognition. It will return no more than one <code>StreamingRecognitionResult<\/code> with the <code>is_final<\/code> flag set to <code>true<\/code>. The <code>single_utterance<\/code> field can only be used with specified models, otherwise an error is thrown. The <code>model<\/code> field in [<code>RecognitionConfig<\/code>][] must be set to: <em> <code>command_and_search<\/code> <\/em> <code>phone_call<\/code> AND additional field <code>useEnhanced<\/code>=<code>true<\/code> * The <code>model<\/code> field is left undefined. In this case the API auto-selects a model based on any other parameters that you set in <code>RecognitionConfig<\/code>.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"optional":null,"nullable":null},{"name":"data.interim_results\n","description":"<p>If <code>true<\/code>, interim results (tentative hypotheses) may be returned as they become available (these interim results are indicated with the <code>is_final=false<\/code> flag). If <code>false<\/code> or omitted, only <code>is_final=true<\/code> result(s) are returned.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getConfig","type":"instance","name":"getConfig","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L106","description":"<p>Required. Provides information to the recognizer that specifies how to\nprocess the request.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v1p1beta1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v1p1beta1\/recognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\RecognitionConfig<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setConfig","type":"instance","name":"setConfig","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L129","description":"<p>Required. Provides information to the recognizer that specifies how to\nprocess the request.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v1p1beta1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. Provides information to the recognizer that specifies how to\nprocess the request.<\/p>\n","types":["<a data-custom-type=\"speech\/v1p1beta1\/recognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\RecognitionConfig<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v1p1beta1\/streamingrecognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\StreamingRecognitionConfig<\/a>"],"description":""}]},{"id":"getSingleUtterance","type":"instance","name":"getSingleUtterance","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L160","description":"<p>If <code>false<\/code> or omitted, the recognizer will perform continuous\nrecognition (continuing to wait for and process audio even if the user\npauses speaking) until the client closes the input stream (gRPC API) or\nuntil the maximum time limit has been reached. May return multiple\n<code>StreamingRecognitionResult<\/code>s with the <code>is_final<\/code> flag set to <code>true<\/code>.<\/p>\n<p>If <code>true<\/code>, the recognizer will detect a single spoken utterance. When it\ndetects that the user has paused or stopped speaking, it will return an\n<code>END_OF_SINGLE_UTTERANCE<\/code> event and cease recognition. It will return no\nmore than one <code>StreamingRecognitionResult<\/code> with the <code>is_final<\/code> flag set to\n<code>true<\/code>.\nThe <code>single_utterance<\/code> field can only be used with specified models,\notherwise an error is thrown. The <code>model<\/code> field in [<code>RecognitionConfig<\/code>][]\nmust be set to:<\/p>\n<ul>\n<li><code>command_and_search<\/code><\/li>\n<li><code>phone_call<\/code> AND additional field <code>useEnhanced<\/code>=<code>true<\/code><\/li>\n<li>The <code>model<\/code> field is left undefined. In this case the API auto-selects\na model based on any other parameters that you set in\n<code>RecognitionConfig<\/code>.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>bool single_utterance = 2;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"description":""}]},{"id":"setSingleUtterance","type":"instance","name":"setSingleUtterance","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L189","description":"<p>If <code>false<\/code> or omitted, the recognizer will perform continuous\nrecognition (continuing to wait for and process audio even if the user\npauses speaking) until the client closes the input stream (gRPC API) or\nuntil the maximum time limit has been reached. May return multiple\n<code>StreamingRecognitionResult<\/code>s with the <code>is_final<\/code> flag set to <code>true<\/code>.<\/p>\n<p>If <code>true<\/code>, the recognizer will detect a single spoken utterance. When it\ndetects that the user has paused or stopped speaking, it will return an\n<code>END_OF_SINGLE_UTTERANCE<\/code> event and cease recognition. It will return no\nmore than one <code>StreamingRecognitionResult<\/code> with the <code>is_final<\/code> flag set to\n<code>true<\/code>.\nThe <code>single_utterance<\/code> field can only be used with specified models,\notherwise an error is thrown. The <code>model<\/code> field in [<code>RecognitionConfig<\/code>][]\nmust be set to:<\/p>\n<ul>\n<li><code>command_and_search<\/code><\/li>\n<li><code>phone_call<\/code> AND additional field <code>useEnhanced<\/code>=<code>true<\/code><\/li>\n<li>The <code>model<\/code> field is left undefined. In this case the API auto-selects\na model based on any other parameters that you set in\n<code>RecognitionConfig<\/code>.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>bool single_utterance = 2;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>If <code>false<\/code> or omitted, the recognizer will perform continuous\nrecognition (continuing to wait for and process audio even if the user\npauses speaking) until the client closes the input stream (gRPC API) or\nuntil the maximum time limit has been reached. May return multiple\n<code>StreamingRecognitionResult<\/code>s with the <code>is_final<\/code> flag set to <code>true<\/code>.<\/p>\n<p>If <code>true<\/code>, the recognizer will detect a single spoken utterance. When it\ndetects that the user has paused or stopped speaking, it will return an\n<code>END_OF_SINGLE_UTTERANCE<\/code> event and cease recognition. It will return no\nmore than one <code>StreamingRecognitionResult<\/code> with the <code>is_final<\/code> flag set to\n<code>true<\/code>.\nThe <code>single_utterance<\/code> field can only be used with specified models,\notherwise an error is thrown. The <code>model<\/code> field in [<code>RecognitionConfig<\/code>][]\nmust be set to:<\/p>\n<ul>\n<li><code>command_and_search<\/code><\/li>\n<li><code>phone_call<\/code> AND additional field <code>useEnhanced<\/code>=<code>true<\/code><\/li>\n<li>The <code>model<\/code> field is left undefined. In this case the API auto-selects\na model based on any other parameters that you set in\n<code>RecognitionConfig<\/code>.<\/li>\n<\/ul>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v1p1beta1\/streamingrecognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\StreamingRecognitionConfig<\/a>"],"description":""}]},{"id":"getInterimResults","type":"instance","name":"getInterimResults","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L206","description":"<p>If <code>true<\/code>, interim results (tentative hypotheses) may be\nreturned as they become available (these interim results are indicated with\nthe <code>is_final=false<\/code> flag).<\/p>\n<p>If <code>false<\/code> or omitted, only <code>is_final=true<\/code> result(s) are returned.<\/p>\n<p>Generated from protobuf field <code>bool interim_results = 3;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"description":""}]},{"id":"setInterimResults","type":"instance","name":"setInterimResults","source":"Speech\/src\/V1p1beta1\/StreamingRecognitionConfig.php#L221","description":"<p>If <code>true<\/code>, interim results (tentative hypotheses) may be\nreturned as they become available (these interim results are indicated with\nthe <code>is_final=false<\/code> flag).<\/p>\n<p>If <code>false<\/code> or omitted, only <code>is_final=true<\/code> result(s) are returned.<\/p>\n<p>Generated from protobuf field <code>bool interim_results = 3;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>If <code>true<\/code>, interim results (tentative hypotheses) may be\nreturned as they become available (these interim results are indicated with\nthe <code>is_final=false<\/code> flag).<\/p>\n<p>If <code>false<\/code> or omitted, only <code>is_final=true<\/code> result(s) are returned.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.boolean.php\" target=\"_blank\">bool<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v1p1beta1\/streamingrecognitionconfig\">Google\\Cloud\\Speech\\V1p1beta1\\StreamingRecognitionConfig<\/a>"],"description":""}]}]}